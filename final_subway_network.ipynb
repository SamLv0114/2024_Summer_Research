{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import my_nx as my_nx\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime,time, timedelta\n",
    "import pickle\n",
    "from process_transfers import get_merged_stops, get_merged_stops_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary datasets\n",
    "base_path = r'C:\\Users\\baodu\\Dropbox\\Summer_research_2024\\google_transit_subway'\n",
    "trips = pd.read_csv(f'{base_path}\\\\filtered_trips.txt')\n",
    "stop_times = pd.read_csv(f'{base_path}\\\\stop_times.txt')\n",
    "stops = pd.read_csv(f'{base_path}\\\\stops.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge these 3 datasets into 1 dataset for easy data processing\n",
    "stop_details = pd.merge(stop_times, trips, on='trip_id')\n",
    "stop_details = pd.merge(stop_details, stops, on='stop_id')\n",
    "stop_details = stop_details.sort_values(by=['trip_id', 'stop_sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the distance of two locations with given lat and lon\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371000\n",
    "    phi1, phi2 = math.radians(lat1), math.radians(lat2)\n",
    "    delta_phi = math.radians(lat2 - lat1)\n",
    "    delta_lambda = math.radians(lon2 - lon1)\n",
    "    a = math.sin(delta_phi / 2)**2 + math.cos(phi1) * math.cos(phi2) * math.sin(delta_lambda / 2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    return R * c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all stations to its parent station if there is one. 101N, 101S -> 101\n",
    "stop_details['stop_id'] = stop_details.apply(lambda row: row['parent_station'] if pd.notna(row['parent_station']) else row['stop_id'], axis=1)\n",
    "stops['stop_id'] = stops.apply(lambda row: row['parent_station'] if pd.notna(row['parent_station']) else row['stop_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store what each stop corresponds to after merging\n",
    "stops_mapping = {}\n",
    "stop_lst = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster stops that are within 200 m\n",
    "G = nx.Graph()\n",
    "\n",
    "for index, row in stops.iterrows():\n",
    "    G.add_node(row['stop_id'], pos=(row['stop_lat'], row['stop_lon']), name=row['stop_name'])\n",
    "    \n",
    "def merge_close_nodes(G, threshold):\n",
    "    pos = nx.get_node_attributes(G, 'pos')\n",
    "    names = nx.get_node_attributes(G, 'name')\n",
    "    nodes = list(G.nodes())\n",
    "    # print(nodes)\n",
    "    \n",
    "    clusters = []\n",
    "    visited = set()\n",
    "    \n",
    "    for node in nodes:\n",
    "        if node not in visited:\n",
    "            cluster = {node}\n",
    "            queue = [node]\n",
    "            visited.add(node)\n",
    "            while queue:\n",
    "                current = queue.pop(0)\n",
    "                current_pos = G.nodes[current]['pos']\n",
    "                for neighbor in nodes:\n",
    "                    if neighbor not in visited:\n",
    "                        neighbor_pos = G.nodes[neighbor]['pos']\n",
    "                        if haversine(current_pos[0], current_pos[1], neighbor_pos[0], neighbor_pos[1]) < threshold:\n",
    "                            visited.add(neighbor)\n",
    "                            queue.append(neighbor)\n",
    "                            cluster.add(neighbor)\n",
    "            clusters.append(cluster)\n",
    "    \n",
    "    for cluster in clusters:\n",
    "        for node in cluster:\n",
    "            str_val = ' '.join(list(map(str, cluster)))\n",
    "            stops_mapping[node] = str_val\n",
    "    \n",
    "    return clusters\n",
    "\n",
    "clusters = merge_close_nodes(G, 200)\n",
    "# print(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map stations to clusters\n",
    "stop_details['stop_id'] = stop_details.apply(lambda row: stops_mapping[row['stop_id']] if row['stop_id'] in stops_mapping else row['stop_id'], axis=1)\n",
    "stops['stop_id'] = stops.apply(lambda row: stops_mapping[row['stop_id']] if row['stop_id'] in stops_mapping else row['stop_id'], axis=1)\n",
    "\n",
    "# get all unique stops after merging\n",
    "stop_lst = stops['stop_id'].unique()\n",
    "# print(stop_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find which routes are availiable at each stop\n",
    "route_per_stop = {}\n",
    "for row in stop_details.itertuples():\n",
    "    if row.stop_id not in route_per_stop:\n",
    "        route_per_stop[row.stop_id] = [row.route_id]\n",
    "    else:\n",
    "        if row.route_id not in route_per_stop[row.stop_id]:\n",
    "            route_per_stop[row.stop_id].append(row.route_id)\n",
    "        else:\n",
    "            continue\n",
    "# route_per_stop\n",
    "stop_details['routes_per_stop'] = stop_details['stop_id'].map(route_per_stop)\n",
    "# print(route_per_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_time(curr_time):\n",
    "    if curr_time == '24:00:00':\n",
    "        return pd.to_datetime('2024-01-01 00:00:00')\n",
    "    else:\n",
    "        try:\n",
    "            return pd.to_datetime(curr_time, format='%H:%M:%S')\n",
    "        \n",
    "        # The following error occurs when the time in the file is above 24:00:00 such as 25:00:00\n",
    "        except ValueError:\n",
    "            h, m, s = map(int, curr_time.split(':'))\n",
    "            h = h % 24\n",
    "            return (datetime(2024, 1, 1, h, m, s) + timedelta(days=h // 24))\n",
    "\n",
    "stop_details['departure_time'] = stop_details['departure_time'].apply(parse_time)\n",
    "stop_details['arrival_time'] =stop_details['arrival_time'].apply(parse_time)\n",
    "# stop_details.to_csv('check.txt')\n",
    "\n",
    "# Separate the data into weekdays and weekends\n",
    "stop_details_weekday = stop_details[stop_details['service_id'] == 'Weekday']\n",
    "stop_details_weekends = stop_details[(stop_details['service_id'] == 'Saturday') | (stop_details['service_id'] == 'Sunday')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build ad\n",
    "def build_matrix(stop_details):\n",
    "    # record how many vehicle trips between every two stops\n",
    "    trip_count = pd.DataFrame(0, index=stop_lst, columns=stop_lst)\n",
    "    \n",
    "    # record the travel time between every two stops\n",
    "    travel_time = pd.DataFrame(0.0, index=stop_lst, columns=stop_lst)\n",
    "    \n",
    "    # Iterate through the stops details to build the matrix\n",
    "    for i in range(len(stop_details)-1):\n",
    "        curr_seq = stop_details.iloc[i]['stop_sequence']\n",
    "        curr_id = stop_details.iloc[i]['stop_id']\n",
    "        next_seq = stop_details.iloc[i+1]['stop_sequence']\n",
    "        next_id = stop_details.iloc[i+1]['stop_id']\n",
    "        \n",
    "        # If this condition meets, we know next_id is the next stop of the curr_id.  \n",
    "        if curr_seq+1 == next_seq:\n",
    "            trip_count.loc[curr_id, next_id] += 1\n",
    "            travel_time.loc[curr_id, next_id] = (stop_details.iloc[i+1]['arrival_time'] - stop_details.iloc[i]['departure_time']).total_seconds() / 60\n",
    "\n",
    "    return trip_count, travel_time\n",
    "\n",
    "# build_matrix(stop_details_weekday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_edge_labels(trip_count, travel_time):\n",
    "    edge_labels ={}\n",
    "    for i in trip_count.index:\n",
    "        for j in trip_count.columns:\n",
    "            if trip_count.loc[i,j] !=0:\n",
    "                edge_labels[(i, j)] = (trip_count.loc[i,j],  travel_time.loc[i,j])\n",
    "    return edge_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_network(clusters, trip_count, travel_time, title):\n",
    "    # Create a new graph with merged nodes\n",
    "    new_G = nx.DiGraph()\n",
    "    \n",
    "    # G is the graph containing all stops before merging\n",
    "    names = nx.get_node_attributes(G, 'name')\n",
    "    nodes = list(G.nodes())\n",
    "    \n",
    "    for cluster in clusters:\n",
    "        # Calculate centroid\n",
    "        lat_sum = sum(G.nodes[node]['pos'][0] for node in cluster)\n",
    "        lon_sum = sum(G.nodes[node]['pos'][1] for node in cluster)\n",
    "        centroid = (lon_sum / len(cluster), lat_sum / len(cluster))\n",
    "        \n",
    "        # Combine names\n",
    "        combined_name = \" / \".join(sorted({names[node] for node in cluster}))\n",
    "        temp_name = ' '.join(list(map(str, cluster)))\n",
    "        new_node = f\"{temp_name}\"\n",
    "        new_G.add_node(new_node, pos=centroid, name=combined_name, routes=route_per_stop[temp_name])\n",
    "\n",
    "    \n",
    "    for i in trip_count.index:\n",
    "        for j in trip_count.columns:\n",
    "            if trip_count.loc[i, j] > 0:  # There is a trip from i to j\n",
    "                routes_i = set(nx.get_node_attributes(new_G, 'routes')[i])\n",
    "                routes_j = set(nx.get_node_attributes(new_G, 'routes')[j])\n",
    "                # Ensure both stops share at least one common route\n",
    "                common_routes = routes_i.intersection(routes_j)\n",
    "                if common_routes:\n",
    "                    new_G.add_edge(i, j, vechicle_trips=trip_count.loc[i, j], travel_time=travel_time.loc[i, j], routes=list(common_routes))\n",
    "    \n",
    "\n",
    "    new_G.remove_edges_from(nx.selfloop_edges(new_G))\n",
    "\n",
    "    # Plot the network\n",
    "    pos = nx.get_node_attributes(new_G, 'pos')\n",
    "    name = nx.get_node_attributes(new_G, 'name')\n",
    "    edge_labels = {(u, v): f\"{d['vechicle_trips']}, {d['travel_time']}\" for u, v, d in new_G.edges(data=True)}\n",
    "\n",
    "    plt.figure(figsize=(40, 30))\n",
    "    nx.draw(new_G, pos, node_size=8, node_color='grey', labels=name, font_color='purple', font_size='12', with_labels=True, arrowsize=20, verticalalignment='bottom', connectionstyle='arc3, rad = 0.1')\n",
    "    \n",
    "    my_nx.my_draw_networkx_edge_labels(new_G, pos=pos, edge_labels=edge_labels, font_color='red', font_size=8, rotate=True, rad=0.1)\n",
    "\n",
    "    plt.show()\n",
    "    plt.savefig(f'{title}', dpi=500)\n",
    "    pickle.dump(new_G, open(f'{title}.pickle', 'wb'))\n",
    "    return new_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekday_trip_count, weekday_travel_time = build_matrix(stop_details_weekday)\n",
    "weekend_trip_count, weekend_travel_time = build_matrix(stop_details_weekends)\n",
    "\n",
    "\n",
    "weekday_trip_count.to_csv('weekday_trip_count.csv')\n",
    "weekend_trip_count.to_csv('weekend_trip_count.csv')\n",
    "\n",
    "weekday_travel_time.to_csv('weekday_travel_time.csv')\n",
    "weekend_travel_time.to_csv('weekend_travel_time.csv')\n",
    "\n",
    "weekday_edge_labels = compute_edge_labels(weekday_trip_count, weekday_travel_time)\n",
    "weekend_edge_labels = compute_edge_labels(weekend_trip_count, weekend_travel_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiGraph with 435 nodes and 1080 edges\n"
     ]
    }
   ],
   "source": [
    "weekday_G = build_network(clusters, weekday_trip_count, weekday_travel_time, 'subway_network_weekday')\n",
    "weekend_G = build_network(clusters, weekend_trip_count, weekend_travel_time, 'subway_network_weekend')\n",
    "print(weekday_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
